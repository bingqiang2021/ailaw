import streamlit as st
from phi.agent import Agent
from phi.knowledge.pdf import PDFKnowledgeBase, PDFReader
from phi.vectordb.qdrant import Qdrant
from phi.tools.duckduckgo import DuckDuckGo
from phi.model.openai import OpenAIChat
from phi.embedder.openai import OpenAIEmbedder
import tempfile
import os

#initializing the session state variables
def init_session_state():
    """Initialize session state variables"""
    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = "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"
    if 'vector_db' not in st.session_state:
        st.session_state.vector_db = None
    if 'legal_team' not in st.session_state:
        st.session_state.legal_team = None
    if 'knowledge_base' not in st.session_state:
        st.session_state.knowledge_base = None

def init_qdrant():
    """Initialize Qdrant vector database"""
    return Qdrant(          
        collection="legal_knowledge",
        path=":memory:",  # Use in-memory storage
        distance="cosine"
    )

def process_document(uploaded_file, vector_db: Qdrant):
    """Process document, create embeddings and store in Qdrant vector database"""
    if not st.session_state.openai_api_key:
        raise ValueError("æœªæä¾›OpenAI APIå¯†é’¥")
        
    os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
    
    with tempfile.TemporaryDirectory() as temp_dir:
      
        temp_file_path = os.path.join(temp_dir, uploaded_file.name)
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        try:
       
            embedder = OpenAIEmbedder(
                model="text-embedding-3-small",
                api_key=st.session_state.openai_api_key
            )
            
            # Creating knowledge base with explicit Qdrant configuration
            knowledge_base = PDFKnowledgeBase(
                path=temp_dir, 
                vector_db=vector_db, 
                reader=PDFReader(chunk=True),
                embedder=embedder,
                recreate_vector_db=True  
            )
            knowledge_base.load()     
            return knowledge_base      
        except Exception as e:
            raise Exception(f"Error processing document: {str(e)}")

def main():
    st.set_page_config(page_title="æ³•å¾‹æ–‡æ¡£åˆ†æå™¨", layout="wide")
    init_session_state()

    st.title("AIæ³•å¾‹é¡¾é—®å›¢é˜Ÿ ğŸ‘¨â€âš–ï¸")

    with st.sidebar:
        st.header("ğŸ”‘ APIé…ç½®")
   
        # OpenAI API key is pre-configured
        st.success("OpenAI APIå¯†é’¥å·²é¢„é…ç½®")
        
        # Initialize in-memory Qdrant
        if not st.session_state.vector_db:
            st.session_state.vector_db = init_qdrant()
            st.success("å†…å­˜æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼")

        st.divider()

        if all([st.session_state.openai_api_key, st.session_state.vector_db]):
            st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
            uploaded_file = st.file_uploader("ä¸Šä¼ æ³•å¾‹æ–‡æ¡£", type=['pdf'])
            
            if uploaded_file:
                with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                    try:
                        knowledge_base = process_document(uploaded_file, st.session_state.vector_db)
                        st.session_state.knowledge_base = knowledge_base
                        
                        # Initialize agents
                        legal_researcher = Agent(
                            name="legal_researcher",
                            role="Legal Research Expert",
                            model=OpenAIChat(model="gpt-4"),
                            tools=[DuckDuckGo()],
                            knowledge=st.session_state.knowledge_base,
                            search_knowledge=True,
                            instructions=[
                                "æŸ¥æ‰¾å¹¶å¼•ç”¨ç›¸å…³æ³•å¾‹æ¡ˆä¾‹å’Œåˆ¤ä¾‹",
                                "æä¾›è¯¦ç»†çš„ç ”ç©¶æ€»ç»“å’Œæ¥æº",
                                "å¼•ç”¨ä¸Šä¼ æ–‡æ¡£ä¸­çš„å…·ä½“ç« èŠ‚",
                                "å§‹ç»ˆæœç´¢çŸ¥è¯†åº“ä»¥è·å–ç›¸å…³ä¿¡æ¯"
                            ],
                            show_tool_calls=True,
                            markdown=True
                        )

                        contract_analyst = Agent(
                            name="contract_analyst",
                            role="Contract Analysis Expert",
                            model=OpenAIChat(model="gpt-4"),
                            knowledge=knowledge_base,
                            search_knowledge=True,
                            instructions=[
                                "å…¨é¢å®¡æŸ¥åˆåŒå†…å®¹",
                                "è¯†åˆ«å…³é”®æ¡æ¬¾å’Œæ½œåœ¨é—®é¢˜",
                                "å¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“æ¡æ¬¾"
                            ],
                            markdown=True
                        )

                        legal_strategist = Agent(
                            name="legal_strategist", 
                            role="Legal Strategy Expert",
                            model=OpenAIChat(model="gpt-4"),
                            knowledge=knowledge_base,
                            search_knowledge=True,
                            instructions=[
                                "åˆ¶å®šå…¨é¢çš„æ³•å¾‹ç­–ç•¥",
                                "æä¾›å¯è¡Œçš„å»ºè®®",
                                "è€ƒè™‘é£é™©å’Œæœºé‡"
                            ],
                            markdown=True
                        )

                        # Legal Agent Team
                        st.session_state.legal_team = Agent(
                            name="legal_team_lead",
                            role="Legal Team Coordinator",
                            model=OpenAIChat(model="gpt-4"),
                            team=[legal_researcher, contract_analyst, legal_strategist],
                            knowledge=st.session_state.knowledge_base,
                            search_knowledge=True,
                            instructions=[
                                "åè°ƒå›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„åˆ†æå·¥ä½œ",
                                "æä¾›å…¨é¢çš„å“åº”",
                                "ç¡®ä¿æ‰€æœ‰å»ºè®®éƒ½æœ‰é€‚å½“çš„æ¥æº",
                                "å¼•ç”¨æ–‡æ¡£çš„å…·ä½“éƒ¨åˆ†",
                                "åœ¨åˆ†é…ä»»åŠ¡å‰å§‹ç»ˆæœç´¢çŸ¥è¯†åº“"
                            ],
                            show_tool_calls=True,
                            markdown=True
                        )
                        
                        st.success("âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå›¢é˜Ÿå·²åˆå§‹åŒ–ï¼")
                            
                    except Exception as e:
                        st.error(f"æ–‡æ¡£å¤„ç†é”™è¯¯: {str(e)}")

            st.divider()
            st.header("ğŸ” åˆ†æé€‰é¡¹")
            analysis_type = st.selectbox(
                "é€‰æ‹©åˆ†æç±»å‹",
                [
                    "åˆåŒå®¡æŸ¥",
                    "æ³•å¾‹ç ”ç©¶",
                    "é£é™©è¯„ä¼°",
                    "åˆè§„æ£€æŸ¥",
                    "è‡ªå®šä¹‰æŸ¥è¯¢"
                ]
            )
        else:
            st.warning("è¯·é…ç½®æ‰€æœ‰APIå‡­æ®ä»¥ç»§ç»­")

    # Main content area
    if not all([st.session_state.openai_api_key, st.session_state.vector_db]):
        st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ é…ç½®APIå‡­æ®ä»¥å¼€å§‹")
    elif not uploaded_file:
        st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ³•å¾‹æ–‡æ¡£ä»¥å¼€å§‹åˆ†æ")
    elif st.session_state.legal_team:
        # Create a dictionary for analysis type icons
        analysis_icons = {
            "åˆåŒå®¡æŸ¥": "ğŸ“‘",
            "æ³•å¾‹ç ”ç©¶": "ğŸ”",
            "é£é™©è¯„ä¼°": "âš ï¸",
            "åˆè§„æ£€æŸ¥": "âœ…",
            "è‡ªå®šä¹‰æŸ¥è¯¢": "ğŸ’­"
        }

        # Dynamic header with icon
        st.header(f"{analysis_icons[analysis_type]} {analysis_type}åˆ†æ")
  
        analysis_configs = {
            "åˆåŒå®¡æŸ¥": {
                "query": "è¯·å®¡æŸ¥æœ¬åˆåŒå¹¶è¯†åˆ«å…³é”®æ¡æ¬¾ã€ä¹‰åŠ¡å’Œæ½œåœ¨é—®é¢˜ã€‚",
                "agents": ["contract_analyst"],
                "description": "è¯¦ç»†çš„åˆåŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æ¡æ¬¾å’Œä¹‰åŠ¡"
            },
            "æ³•å¾‹ç ”ç©¶": {
                "query": "ç ”ç©¶ä¸æœ¬æ–‡æ¡£ç›¸å…³çš„æ¡ˆä¾‹å’Œåˆ¤ä¾‹ã€‚",
                "agents": ["legal_researcher"],
                "description": "ç›¸å…³æ³•å¾‹æ¡ˆä¾‹å’Œåˆ¤ä¾‹ç ”ç©¶"
            },
            "é£é™©è¯„ä¼°": {
                "query": "åˆ†ææœ¬æ–‡æ¡£ä¸­çš„æ½œåœ¨æ³•å¾‹é£é™©å’Œè´£ä»»ã€‚",
                "agents": ["contract_analyst", "legal_strategist"],
                "description": "ç»¼åˆé£é™©åˆ†æå’Œæˆ˜ç•¥è¯„ä¼°"
            },
            "åˆè§„æ£€æŸ¥": {
                "query": "æ£€æŸ¥æœ¬æ–‡æ¡£çš„ç›‘ç®¡åˆè§„æ€§é—®é¢˜ã€‚",
                "agents": ["legal_researcher", "contract_analyst", "legal_strategist"],
                "description": "å…¨é¢çš„åˆè§„æ€§åˆ†æ"
            },
            "è‡ªå®šä¹‰æŸ¥è¯¢": {
                "query": None,
                "agents": ["legal_researcher", "contract_analyst", "legal_strategist"],
                "description": "ä½¿ç”¨æ‰€æœ‰å¯ç”¨ä»£ç†è¿›è¡Œè‡ªå®šä¹‰åˆ†æ"
            }
        }

        st.info(f"ğŸ“‹ {analysis_configs[analysis_type]['description']}")
        # Agent name mapping
        agent_names = {
            "legal_researcher": "æ³•å¾‹ç ”ç©¶å‘˜",
            "contract_analyst": "åˆåŒåˆ†æå¸ˆ",
            "legal_strategist": "æ³•å¾‹ç­–ç•¥å¸ˆ",
            "legal_team_lead": "æ³•å¾‹å›¢é˜Ÿè´Ÿè´£äºº"
        }
        
        # Convert agent IDs to display names
        active_agents = [agent_names[agent] for agent in analysis_configs[analysis_type]['agents']]
        st.write(f"ğŸ¤– å½“å‰æ´»åŠ¨çš„æ³•å¾‹AIä¸“å®¶: {', '.join(active_agents)}")

        # Replace the existing user_query section with this:
        if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢":
            user_query = st.text_area(
                "è¯·è¾“å…¥æ‚¨çš„å…·ä½“é—®é¢˜ï¼š",
                help="æ·»åŠ æ‚¨æƒ³è¦åˆ†æçš„å…·ä½“é—®é¢˜æˆ–è¦ç‚¹"
            )
        else:
            user_query = None  # Set to None for non-custom queries


        if st.button("å¼€å§‹åˆ†æ"):
            if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢" and not user_query:
                st.warning("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
            else:
                with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    try:
                        # Ensure OpenAI API key is set
                        os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
                        
                        # Combine predefined and user queries
                        if analysis_type != "è‡ªå®šä¹‰æŸ¥è¯¢":
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            ä¸»è¦åˆ†æä»»åŠ¡ï¼š{analysis_configs[analysis_type]['query']}
                            å…³æ³¨é¢†åŸŸï¼š{', '.join(analysis_configs[analysis_type]['agents'])}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å‚è€ƒå†…å®¹ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚
                            """
                        else:
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            {user_query}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å‚è€ƒå†…å®¹ã€‚
                            å…³æ³¨é¢†åŸŸï¼š{', '.join(analysis_configs[analysis_type]['agents'])}
                            è¯·ç”¨ä¸­æ–‡å›å¤ã€‚
                            """

                        response = st.session_state.legal_team.run(combined_query)
                        
                        # Display results in tabs
                        tabs = st.tabs(["åˆ†æ", "è¦ç‚¹", "å»ºè®®"])
                        
                        with tabs[0]:
                            st.markdown("### è¯¦ç»†åˆ†æ")
                            if response.content:
                                st.markdown(response.content)
                            else:
                                for message in response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[1]:
                            st.markdown("### å…³é”®è¦ç‚¹")
                            key_points_response = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š    
                                {response.content}
                                
                                è¯·ç”¨è¦ç‚¹åˆ—è¡¨æ€»ç»“å…³é”®å†…å®¹ã€‚
                                é‡ç‚¹å…³æ³¨æ¥è‡ªä»¥ä¸‹ä¸“å®¶çš„è§è§£ï¼š{', '.join([agent_names[agent] for agent in analysis_configs[analysis_type]['agents']])}
                                è¯·ç”¨ä¸­æ–‡å›å¤ã€‚"""
                            )
                            if key_points_response.content:
                                st.markdown(key_points_response.content)
                            else:
                                for message in key_points_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[2]:
                            st.markdown("### å»ºè®®")
                            recommendations_response = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š
                                {response.content}
                                
                                æ ¹æ®åˆ†æç»“æœï¼Œæ‚¨çš„ä¸»è¦å»ºè®®å’Œæœ€ä½³è¡ŒåŠ¨æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ
                                è¯·æä¾›æ¥è‡ªä»¥ä¸‹ä¸“å®¶çš„å…·ä½“å»ºè®®ï¼š{', '.join([agent_names[agent] for agent in analysis_configs[analysis_type]['agents']])}
                                è¯·ç”¨ä¸­æ–‡å›å¤ã€‚"""
                            )
                            if recommendations_response.content:
                                st.markdown(recommendations_response.content)
                            else:
                                for message in recommendations_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)

                    except Exception as e:
                        st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    else:
        st.info("è¯·ä¸Šä¼ æ³•å¾‹æ–‡æ¡£ä»¥å¼€å§‹åˆ†æ")

if __name__ == "__main__":
    main()
